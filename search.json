[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ethan Campbell",
    "section": "",
    "text": "Textual Analysis\n\n\n\n\n\nAnalyzing English premier league team’s and how their langauge chagnes during the course of the season\n\n\n\n\n\n\nOct 30, 2022\n\n\nEthan Campbell\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/TextualAnalysis.html",
    "href": "posts/TextualAnalysis.html",
    "title": "Textual Analysis",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/TextualAnalysis.html#arsenal",
    "href": "posts/TextualAnalysis.html#arsenal",
    "title": "Textual Analysis",
    "section": "Arsenal",
    "text": "Arsenal\nThis data was scraped from the official Arsenal page. This scraping pulled in all the matches that have been played this season thus far and will continue to grow as the season progresses. Within this scraped data there was a lot that needed to get removed which included things like /n, , random number strings, and long sentences talking about buying Arsenal pictures. After using stringr to clean up the data we unlisted it and started moving towards a corpus. There is still some tidying that needs to be done to remove some -’s and to make some spaces at certain portion of the document. After cleaning this data was put into a character vector and then put into a corpus which can be found at the bottom of this code. I added in the name of the team and the match number to the table and after that we can start looking at what the data means. So far 7 matches have been played and the word count was kept fairly consistent until match 5\n\n\nCode\n## The function is working at reading in the data however. parts of the cleaning process are failing and I am thinking this is because I am not specifying the create values\n\n# I need to remove punct, capitalization, stopwords like (the, a ',') finish repeating the process to all teams and adjusting the function until it grabs every single problem once this is complete we should be able to tokenize then corpus and work with the data\n\nWeb_scrape_function_Arsenal <- function(url,css,data) { # creating function to repeat web scrape \n  url <- read_html(url) \ncss <- (\".article-body\")\ndata <- url %>% \n  html_node(css = css) %>%\n  html_text2()\ndata <- str_replace_all(data, \"\\n\", \"####\") %>%\n  str_replace_all(\"/n\", \"####\") %>%\n  str_remove_all(\"/n\") %>%\n  str_remove_all(\"\\n\") %>%\n  str_remove_all(\" - \") %>%\n  str_replace_all(\"[0-9] of [1234567890]To buy official Arsenal pictures visit Arsenal Pics\", \"#\") %>%\n  str_replace_all(\"[1234567890] of 42To buy official Arsenal pictures visit Arsenal Pics\", \"#\") %>%\n  str_replace_all(\"[1234567890] of 29To buy official Arsenal pictures visit Arsenal Pics\", \"#\") %>%\n  str_replace_all(\"[1234567890] of 45To buy official Arsenal pictures visit Arsenal Pics\", \"#\") %>%\n  str_replace_all(\"[1234567890] of 38To buy official Arsenal pictures visit Arsenal Pics\", \"#\") %>%\n  str_replace_all(\"[1234567890] of 32To buy official Arsenal pictures visit Arsenal Pics\", \"#\") %>%\n  str_remove(\"Play videoWatch Arsenal video online05:24Highlights | Crystal Palace 0-2 Arsenal - bitesize\") %>%\n  str_remove(\"111111111122222222223333333333444\") %>%\n  str_remove_all(\"\\\\(\") %>%\n  str_remove_all(\"\\\\)\") %>%\n  str_remove_all(\"#\") %>%\n  unlist()\n}\n\n\nArsenal_url <- \"https://www.arsenal.com/fixture/arsenal/2022-Aug-05/crystal-palace-0-2-arsenal-match-report\"\nMatch_1 <- Web_scrape_function_Arsenal(Arsenal_url)\n\nArsenal_url <- \"https://www.arsenal.com/fixture/arsenal/2022-Aug-13/arsenal-4-2-leicester-city-match-report\"\nMatch_2 <- Web_scrape_function_Arsenal(Arsenal_url)\n\n\nArsenal_url <- \"https://www.arsenal.com/premier-league-match-report-bournemouth-odegaard-saliba-jesus\"\nMatch_3 <- Web_scrape_function_Arsenal(Arsenal_url)\n\nArsenal_url <- \"https://www.arsenal.com/premier-league-match-report-fulham-odegaard-gabriel\"\nMatch_4 <- Web_scrape_function_Arsenal(Arsenal_url)\n\nArsenal_url <- \"https://www.arsenal.com/match-report-aston-villa-premier-league-martinelli-jesus\"\nMatch_5 <- Web_scrape_function_Arsenal(Arsenal_url)\n\nArsenal_url <- \"https://www.arsenal.com/fixture/arsenal/2022-Sep-04/manchester-united-3-1-arsenal-match-report\"\nMatch_6 <- Web_scrape_function_Arsenal(Arsenal_url)\n\nArsenal_url <- \"https://www.arsenal.com/premier-league-match-report-brentford-saliba-jesus-vieira\"\nMatch_7 <- Web_scrape_function_Arsenal(Arsenal_url)\n\nArsenal <- c(Match_1, Match_2, Match_3, Match_4, Match_5, Match_6, Match_7)\n\nnchar(Arsenal)\n\n\n[1] 8163 9066 7726 7601 4433 7322 7818\n\n\nCode\nArsenal_corpus <- corpus(Arsenal)\n\n\n\nArsenal_corpus_summary <- summary(Arsenal_corpus)\ndocvars(Arsenal_corpus) <- Arsenal_corpus_summary\n# Adding team name\nArsenal_corpus_summary$Team <- \"Arsenal\"\n\n\n# create a Match number\nArsenal_corpus_summary$Match <- as.numeric(str_extract(Arsenal_corpus_summary$Text, \"[0-9]+\"))\nArsenal_corpus_summary\n\n\nCorpus consisting of 7 documents, showing 7 documents:\n\n  Text Types Tokens Sentences    Team Match\n text1   523   1412        11 Arsenal     1\n text2   602   1623        22 Arsenal     2\n text3   551   1387        15 Arsenal     3\n text4   479   1299         9 Arsenal     4\n text5   408    790        12 Arsenal     5\n text6   481   1258         6 Arsenal     6\n text7   526   1395        21 Arsenal     7\n\n\nCode\n# Document feature matrix\nArsenal_dfm <- dfm(tokens(Arsenal_corpus,\n                          remove_punct = TRUE,\n                          remove_symbols = TRUE) %>%\n                     dfm(tolower = TRUE) %>%\n                     dfm_remove(stopwords('english')))\n\nview(Arsenal_dfm)\n\ntopfeatures(Arsenal_dfm, 20)\n\n\n arsenal official      buy pictures    visit   league    first  premier \n     475      223      222      222      222       63       60       57 \n minutes     45to     42to     38to     36to     goal    jesus     32to \n      49       45       42       38       36       33       33       32 \n      us     ball     back     29to \n      31       31       29       29 \n\n\nCode\nset.seed(1)\n\n# draw the wordcloud\ntextplot_wordcloud(Arsenal_dfm, min_count = 20, random_order = FALSE)\n\n\n\n\n\nCode\n# comparing the first and last game\n\nArsenal_small_dfm <- Arsenal_dfm[c(1,7),]\n\n# draw the wordcloud\ntextplot_wordcloud(Arsenal_small_dfm, comparison = TRUE, min_count = 5, random_order = FALSE)\n\n\n\n\n\nCode\n# Creating a table to show the highest frequncy items and then ranking them\nword_counts <- as.data.frame(sort(colSums(Arsenal_dfm),dec=T))\ncolnames(word_counts) <- c(\"Frequency\")\nword_counts$Rank <- c(1:ncol(Arsenal_dfm))\nhead(word_counts)\n\n\n         Frequency Rank\narsenal        475    1\nofficial       223    2\nbuy            222    3\npictures       222    4\nvisit          222    5\nleague          63    6\n\n\nCode\n# zipf's law is really quite accurate as the data does fall off really quickly\nggplot(word_counts, mapping = aes(x = Rank, y = Frequency)) + \n  geom_point() +\n  labs(title = \"Zipf's Law\", x = \"Rank\", y = \"Frequency\") + \n  theme_bw()\n\n\n\n\n\nCode\nArsenal_smaller_dfm <- dfm_trim(Arsenal_dfm, min_termfreq = 10)\n\n# trim based on the proportion of documents that the feature appears in; here, \n# the feature needs to appear in more than 10% of documents (chapters)\nArsenal_smaller_dfm <- dfm_trim(Arsenal_smaller_dfm, min_docfreq = 0.1, docfreq_type = \"prop\")\n\nArsenal_smaller_dfm\n\n\nDocument-feature matrix of: 7 documents, 67 features (18.12% sparse) and 4 docvars.\n       features\ndocs    gabriel martinelli header goal premier league start win home minutes\n  text1       2          3      2    6       9      8     4   3    3      10\n  text2       3          6      3    4       5      5     2   1    3       9\n  text3       3          3      1    8      10     11     5   2    1       7\n  text4       7          4      2    4       8      8     3   3    3       9\n  text5       4          5      0    5       7      9     1   0    0       5\n  text6       2          5      1    5       5      7     2   1    0       6\n[ reached max_ndoc ... 1 more document, reached max_nfeat ... 57 more features ]\n\n\nCode\ntextplot_wordcloud(Arsenal_smaller_dfm, min_count = 50,\n                   random_order = FALSE)\n\n\n\n\n\nCode\n# Creating the FCM\n\nArsenal_smaller_dfm <- dfm_trim(Arsenal_dfm, min_termfreq = 20)\nArsenal_smaller_dfm <- dfm_trim(Arsenal_smaller_dfm, min_docfreq = .3, docfreq_type = \"prop\")\n\n# create fcm from dfm\nArsenal_smaller_dfm <- fcm(Arsenal_smaller_dfm)\n\n# check the dimensions (i.e., the number of rows and the number of columnns)\n# of the matrix we created\ndim(Arsenal_smaller_dfm)\n\n\n[1] 22 22\n\n\nCode\n# pull the top features\nmyFeatures <- names(topfeatures(Arsenal_smaller_dfm, 30))\n\n# retain only those top features as part of our matrix\nArsenal_smaller_dfm <- fcm_select(Arsenal_smaller_dfm, pattern = myFeatures, selection = \"keep\")\n\n# check dimensions\ndim(Arsenal_smaller_dfm)\n\n\n[1] 22 22\n\n\nCode\n# compute size weight for vertices in network\nsize <- log(colSums(Arsenal_smaller_dfm))\n\n# create plot\ntextplot_network(Arsenal_smaller_dfm, vertex_size = size / max(size) * 3)"
  },
  {
    "objectID": "posts/TextualAnalysis.html#manchester-city",
    "href": "posts/TextualAnalysis.html#manchester-city",
    "title": "Textual Analysis",
    "section": "Manchester City",
    "text": "Manchester City\nManchester Cty followed a very similar path as Arsenal as this one also required a lot cleaning with stringr however, it had a few unique moments. For example, I had to clean () which were all over the place in the original data. Other than this portion the cleaning process was the same and this will also needs some additional cleaning. I was able to move this into the corpus as well and we noticed that it had more sentences than Arsenal. However, this could be do to the spacing problem that I mentioned above more studying will need to be done after that change has been made. This team also had a more consistent amount of words and unique words.\n\n\nCode\nWeb_scrape_function_mancity <- function(url,css,data) { # creating function to repeat web scrape \n  url <- read_html(url) \ncss <- (\".article-body__article-text\")\ndata <- url %>% \n  html_node(css = css) %>%\n  html_text2()\ndata <- str_replace_all(data, \"\\n\", \"####\") %>%\n  str_replace_all(\"/n\", \"####\") %>%\n  str_remove_all(\"/n\") %>%\n  str_remove_all(\"\\n\") %>%\n  str_remove_all(\" - \") %>%\n  str_remove_all(\"\\\\(\") %>%\n  str_remove_all(\"\\\\)\") %>%\n  str_remove_all(\"#\") %>%\n  unlist()\n}\n\nmancity_url <- \"https://www.mancity.com/news/mens/west-ham-v-manchester-city-premier-league-match-report-63795480\"\nMatch_1 <- Web_scrape_function_mancity(mancity_url)\n\nmancity_url <- \"https://www.mancity.com/news/mens/man-city-bournemouth-premier-league-match-report-63795987\"\nMatch_2 <- Web_scrape_function_mancity(mancity_url)\n\nmancity_url <- \"https://www.mancity.com/news/mens/newcastle-v-manchester-city-match-report-63796690\"\nMatch_3 <- Web_scrape_function_mancity(mancity_url)\n\nmancity_url <- \"https://www.mancity.com/news/mens/man-city-crystal-palace-match-report-63797204\"\nMatch_4 <- Web_scrape_function_mancity(mancity_url)\n\nmancity_url <- \"https://www.mancity.com/news/mens/manchester-city-v-nottingham-forest-match-report-31-august-63797573\"\nMatch_5 <- Web_scrape_function_mancity(mancity_url)\n\nmancity_url <- \"https://www.mancity.com/news/mens/aston-villa-manchester-city-premier-league-match-report-63797816\"\nMatch_6 <- Web_scrape_function_mancity(mancity_url)\n\nmancity_url <- \"https://www.mancity.com/news/mens/wolves-manchester-city-away-premier-league-2022-match-report-63799002\"\nMatch_7 <- Web_scrape_function_mancity(mancity_url)\n\n\nManCity <- c(Match_1, Match_2, Match_3, Match_4, Match_5, Match_6, Match_7)\n\nMancity_corpus <- corpus(ManCity)\n\nMancity_corpus_summary <- summary(Mancity_corpus)\n\n# Creating a Team Name \nMancity_corpus_summary$Team <- \"Manchester City\"\n\n# create a Match number\nMancity_corpus_summary$Match <- as.numeric(str_extract(Mancity_corpus_summary$Text, \"[0-9]+\"))\nMancity_corpus_summary\n\n\nCorpus consisting of 7 documents, showing 7 documents:\n\n  Text Types Tokens Sentences            Team Match\n text1   564   1270        21 Manchester City     1\n text2   615   1482        28 Manchester City     2\n text3   660   1462        20 Manchester City     3\n text4   550   1218        23 Manchester City     4\n text5   489   1126        34 Manchester City     5\n text6   661   1744        60 Manchester City     6\n text7   703   1724        34 Manchester City     7"
  },
  {
    "objectID": "posts/TextualAnalysis.html#newcastle-united",
    "href": "posts/TextualAnalysis.html#newcastle-united",
    "title": "Textual Analysis",
    "section": "Newcastle united",
    "text": "Newcastle united\nThis is the start of the middle table teams which I am exciting to see how they differ the two top tier teams. This data was scraped from the Newcastle official website and the cleaning process was pretty straight forward on this one as there was nothing unique that needed to be changed. One noticeable difference between this team and the top teams is the amount of words used in match reports as this one is about half of the first two teams. This might be unique to just this team or maybe the lower in the league the team is the less they will write about their performance?\n\n\nCode\n# New Castle United first match against nottingham forest\n# 1 rule for 1 bots crawl delay 5 seconds, scrapable\n\nbow(\"https://www.nufc.co.uk/matches/first-team/2022-23/newcastle-united-v-nottingham-forest/\")\n\n\n<polite session> https://www.nufc.co.uk/matches/first-team/2022-23/newcastle-united-v-nottingham-forest/\n    User-agent: polite R package\n    robots.txt: 1 rules are defined for 1 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n\n\nCode\nWeb_scrape_function_Newcastle <- function(url,css,data) { # creating function to repeat web scrape \n  url <- read_html(url) \ncss <- (\".article__body\")\ndata <- url %>% \n  html_node(css = css) %>%\n  html_text2()\ndata <- str_replace_all(data, \"\\n\", \"####\") %>%\n  str_replace_all(\"/n\", \"####\") %>%\n  str_remove_all(\"/n\") %>%\n  str_remove_all(\"\\n\") %>%\n  str_remove_all(\" - \") %>%\n  str_remove_all(\"\\\\(\") %>%\n  str_remove_all(\"\\\\)\") %>%\n  str_remove_all(\"\\\"\") %>%\n  str_remove_all(\"#\") %>%\n  unlist()\n}\n\nNewcastle_url <- \"https://www.nufc.co.uk/matches/first-team/2022-23/newcastle-united-v-nottingham-forest/\"\nMatch_1 <- Web_scrape_function_Newcastle(Newcastle_url)\n\nNewcastle_url <- \"https://www.nufc.co.uk/matches/first-team/2022-23/brighton-and-hove-albion-v-newcastle-united/\"\nMatch_2 <- Web_scrape_function_Newcastle(Newcastle_url)\n\nNewcastle_url <- \"https://www.nufc.co.uk/matches/first-team/2022-23/newcastle-united-v-manchester-city/\"\nMatch_3 <- Web_scrape_function_Newcastle(Newcastle_url)\n\nNewcastle_url <- \"https://www.nufc.co.uk/matches/first-team/2022-23/wolverhampton-wanderers-v-newcastle-united/\"\nMatch_4 <- Web_scrape_function_Newcastle(Newcastle_url)\n\nNewcastle_url <- \"https://www.nufc.co.uk/matches/first-team/2022-23/liverpool-v-newcastle-united/\"\nMatch_5 <- Web_scrape_function_Newcastle(Newcastle_url)\n\nNewcastle_url <- \"https://www.nufc.co.uk/matches/first-team/2022-23/newcastle-united-v-crystal-palace/\"\nMatch_6 <- Web_scrape_function_Newcastle(Newcastle_url)\n\nNewcastle_url <- \"https://www.nufc.co.uk/matches/first-team/2022-23/newcastle-united-v-bournemouth/\"\nMatch_7 <- Web_scrape_function_Newcastle(Newcastle_url)\n\nNewCastle <- c(Match_1, Match_2, Match_3, Match_4, Match_5, Match_6, Match_7)\n\nNewcastle_corpus <- corpus(NewCastle)\n\nNewcastle_corpus_summary <- summary(Newcastle_corpus)\n\n# Creating a team name\nNewcastle_corpus_summary$Team <- \"New Castle\"\n\n# create a Match number\nNewcastle_corpus_summary$Match <- as.numeric(str_extract(Newcastle_corpus_summary$Text, \"[0-9]+\"))\nNewcastle_corpus_summary\n\n\nCorpus consisting of 7 documents, showing 7 documents:\n\n  Text Types Tokens Sentences       Team Match\n text1   336    665        11 New Castle     1\n text2   336    613        12 New Castle     2\n text3   340    677        12 New Castle     3\n text4   294    539         8 New Castle     4\n text5   324    615         8 New Castle     5\n text6   361    759        19 New Castle     6\n text7   377    741        19 New Castle     7"
  },
  {
    "objectID": "posts/TextualAnalysis.html#everton",
    "href": "posts/TextualAnalysis.html#everton",
    "title": "Textual Analysis",
    "section": "Everton",
    "text": "Everton\nWas going to use Aston Villa originally however, the web scrapping was not returning the correct information so we switched to Everton which is running much more smoothly. This is the second team on the list of middle-tier teams and their cleaning process was about the same as the last team however, Aston Villa’s website was really hard to scrape from. Looking at the corpus information for Everton we notice an increase in words compared to the last team however, there is one match that is significantly higher than the rest. This is match 2 which was against Aston Villa and I am currently unsure why there is such a difference between these amounts.\n\n\nCode\n# Everton vs Chelsea\n# 1 rule for 1 bots crawl delay 5 seconds, scrapable\n\nbow(\"https://www.evertonfc.com/match/74913/everton-chelsea#report\")\n\n\n<polite session> https://www.evertonfc.com/match/74913/everton-chelsea#report\n    User-agent: polite R package\n    robots.txt: 1 rules are defined for 1 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n\n\nCode\nWeb_scrape_function_Everton <- function(url,css,data) { # creating function to repeat web scrape \n  url <- read_html(url) \ncss <- (\".article__body.mc-report__body.js-article-body\")\ndata <- url %>% \n  html_node(css = css) %>%\n  html_text2()\ndata <- str_replace_all(data, \"\\n\", \"####\") %>%\n  str_replace_all(\"/n\", \"####\") %>%\n  str_remove_all(\"/n\") %>%\n  str_remove_all(\"\\n\") %>%\n  str_remove_all(\" - \") %>%\n  str_remove_all(\"\\\\(\") %>%\n  str_remove_all(\"\\\\)\") %>%\n  str_remove_all(\"\\\"\") %>%\n  str_remove_all(\"#\") %>%\n  unlist()\n}\n\nEverton_url <- \"https://www.evertonfc.com/match/74913/everton-chelsea#report\"\nMatch_1 <- Web_scrape_function_Everton(Everton_url)\n\nEverton_url <- \"https://www.evertonfc.com/match/74922/aston-villa-everton#report\"\nMatch_2 <- Web_scrape_function_Everton(Everton_url)\n\nEverton_url <- \"https://www.evertonfc.com/match/74933/everton-nottm-forest#report\"\nMatch_3 <- Web_scrape_function_Everton(Everton_url)\n\nEverton_url <-\"https://www.evertonfc.com/match/74943/brentford-everton#report\"\nMatch_4 <- Web_scrape_function_Everton(Everton_url)\n\nEverton_url <- \"https://www.evertonfc.com/match/74955/leeds-everton#report\"\nMatch_5 <- Web_scrape_function_Everton(Everton_url)\n\nEverton_url <- \"https://www.evertonfc.com/match/74965/everton-liverpool#report\"\nMatch_6 <- Web_scrape_function_Everton(Everton_url)\n\nEverton_url <- \"https://www.evertonfc.com/match/74985/everton-west-ham#report\"\nMatch_7 <- Web_scrape_function_Everton(Everton_url)\n\n\nEverton <- c(Match_1, Match_2, Match_3, Match_4, Match_5, Match_6, Match_7)\n\nEverton_corpus <- corpus(Everton)\n\nEverton_corpus_summary <- summary(Everton_corpus)\n\n# Creating a team name\nEverton_corpus_summary$Team <- \"Everton\"\n\n# create a match indicator\nEverton_corpus_summary$Match <- as.numeric(str_extract(Everton_corpus_summary$Text, \"[0-9]+\"))\nEverton_corpus_summary\n\n\nCorpus consisting of 7 documents, showing 7 documents:\n\n  Text Types Tokens Sentences    Team Match\n text1   516    990         6 Everton     1\n text2   703   1577        13 Everton     2\n text3   330    624         1 Everton     3\n text4   340    614         3 Everton     4\n text5   374    709         4 Everton     5\n text6   418    872         4 Everton     6\n text7   438    874        10 Everton     7"
  },
  {
    "objectID": "posts/TextualAnalysis.html#leicester",
    "href": "posts/TextualAnalysis.html#leicester",
    "title": "Textual Analysis",
    "section": "Leicester",
    "text": "Leicester\nThis is the start of the bottom tier teams and we start to get a look into teams that are in the relegation zone which means that if they do not start improving their performance they will get moved down to the second league. I am expecting some urgency from this team and I am expecting that each match means a lot more to a team like this where one win can seperate you from staying or getting kicked out of the league. The cleaning process went smoothly with this team but there is deffiently still some work that needs to be done before the real analysis. We noticed that there words used was higher than the two middle teams on average and they had a pretty consistent range.\n\n\nCode\n# Leicester against Brentford\n# 1 bot 1 rule scrapable 5 second crawl\nbow(\"https://www.lcfc.com/news/2729025/city-held-by-bees-in-premier-league-opener/featured\")\n\n\n<polite session> https://www.lcfc.com/news/2729025/city-held-by-bees-in-premier-league-opener/featured\n    User-agent: polite R package\n    robots.txt: 1 rules are defined for 1 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n\n\nCode\nWeb_scrape_function_Leicester <- function(url,css,data) { # creating function to repeat web scrape \n  url <- read_html(url) \ncss <- (\".col-12\")\ndata <- url %>% \n  html_node(css = css) %>%\n  html_text2()\ndata <- str_replace_all(data, \"\\n\", \"####\") %>%\n  str_replace_all(\"/n\", \"####\") %>%\n  str_remove_all(\"/n\") %>%\n  str_remove_all(\"\\n\") %>%\n  str_remove_all(\" - \") %>%\n  str_remove_all(\"\\\\(\") %>%\n  str_remove_all(\"\\\\)\") %>%\n  str_remove_all(\"\\\"\") %>%\n  str_remove_all(\"#\") %>%\n  str_remove_all(\"More on this story. . . In Photos -\") %>%\n  unlist()\n}\n\nLeicester_url <- \"https://www.lcfc.com/news/2729025/city-held-by-bees-in-premier-league-opener/featured\"\nMatch_1 <- Web_scrape_function_Leicester(Leicester_url)\n\nLeicester_url <- \"https://www.lcfc.com/news/2739798/foxes-fall-to-defeat-at-arsenal/featured\"\nMatch_2 <- Web_scrape_function_Leicester(Leicester_url)\n\nLeicester_url <- \"https://www.lcfc.com/news/2751347/saints-take-the-points-on-filbert-way/featured\"\nMatch_3 <- Web_scrape_function_Leicester(Leicester_url)\n\nLeicester_url <- \"https://www.lcfc.com/news/2762326/city-defeated-as-10man-chelsea-win-at-stamford-bridge/featured\"\nMatch_4 <- Web_scrape_function_Leicester(Leicester_url)\n\nLeicester_url <- \"https://www.lcfc.com/news/2774578/man-utd-defeat-for-leicester-on-matchday-five/featured\"\nMatch_5 <- Web_scrape_function_Leicester(Leicester_url)\n\nLeicester_url <- \"https://www.lcfc.com/news/2779658/city-beaten-away-to-brighton/featured\"\nMatch_6 <- Web_scrape_function_Leicester(Leicester_url)\n\nLeicester_url <- \"https://www.lcfc.com/news/2793845/leicester-lose-to-spurs-in-london/featured\"\nMatch_7 <- Web_scrape_function_Leicester(Leicester_url)\n\nLeicester <- c(Match_1, Match_2, Match_3, Match_4, Match_5, Match_6, Match_7)\n\nLeicester_corpus <- corpus(Leicester)\n\nLeicester_corpus_summary <- summary(Leicester_corpus)\n\n# Creating a team name\nLeicester_corpus_summary$Team <- \"Leicester\"\n\n# create a match indicator\nLeicester_corpus_summary$Match <- as.numeric(str_extract(Leicester_corpus_summary$Text, \"[0-9]+\"))\nLeicester_corpus_summary\n\n\nCorpus consisting of 7 documents, showing 7 documents:\n\n  Text Types Tokens Sentences      Team Match\n text1   533   1143        26 Leicester     1\n text2   539   1183        18 Leicester     2\n text3   484   1043        39 Leicester     3\n text4   557   1263        27 Leicester     4\n text5   463    830        36 Leicester     5\n text6   498   1071        20 Leicester     6\n text7   481    999        26 Leicester     7"
  },
  {
    "objectID": "posts/TextualAnalysis.html#west-ham-united",
    "href": "posts/TextualAnalysis.html#west-ham-united",
    "title": "Textual Analysis",
    "section": "West Ham United",
    "text": "West Ham United\nWest Ham was fairly straight forward and I was able to clean this one pretty well. There is still some spacing work that needs to be done but that will come at a later stage. When looking at their information we noticed that they use some of the least amount of words when talking about the matches. They also use some of the least unique words so I am interested to break this one down and see if they are mostly talking about certain players performances.\n\n\nCode\n# West Ham vs Manchester City\n\nWeb_scrape_function_WestHam <- function(url,css,data) { # creating function to repeat web scrape \n  url <- read_html(url) \ncss <- (\".m-article__columns\")\ndata <- url %>% \n  html_node(css = css) %>%\n  html_text2()\ndata <- str_replace_all(data, \"\\n\", \"####\") %>%\n  str_replace_all(\"/n\", \"####\") %>%\n  str_remove_all(\"/n\") %>%\n  str_remove_all(\"\\n\") %>%\n  str_remove_all(\" - \") %>%\n  str_remove_all(\"\\\\(\") %>%\n  str_remove_all(\"\\\\)\") %>%\n  str_remove_all(\"\\\"\") %>%\n  str_remove_all(\"#\") %>%\n  str_remove_all(\"More on this story. . . In Photos -\") %>%\n  unlist()\n}\n\nWestHam_url <- \"https://www.whufc.com/fixture/view/6472\"\nMatch_1 <- Web_scrape_function_WestHam(WestHam_url)\n\nWestHam_url <- \"https://www.whufc.com/fixture/view/6464\"\nMatch_2 <- Web_scrape_function_WestHam(WestHam_url)\n\nWestHam_url <- \"https://www.whufc.com/fixture/view/6452\"\nMatch_3 <- Web_scrape_function_WestHam(WestHam_url)\n\nWestHam_url <- \"https://www.whufc.com/fixture/view/6450\"\nMatch_4 <- Web_scrape_function_WestHam(WestHam_url)\n\nWestHam_url <- \"https://www.whufc.com/fixture/view/6436\"\nMatch_5 <- Web_scrape_function_WestHam(WestHam_url)\n\nWestHam_url <- \"https://www.whufc.com/fixture/view/6428\"\nMatch_6 <- Web_scrape_function_WestHam(WestHam_url)\n\nWestHam_url <- \"https://www.whufc.com/fixture/view/6407\"\nMatch_7 <- Web_scrape_function_WestHam(WestHam_url)\n\n\nWestham <- c(Match_1, Match_2, Match_3, Match_4, Match_5, Match_6, Match_7)\n\nWestham_corpus <- corpus(Westham)\n\nWestham_corpus_summary <- summary(Westham_corpus)\n\n# Creating a team name\nWestham_corpus_summary$Team <- \"WestHam\"\n\n\n# create a match indicator\nWestham_corpus_summary$Match <- as.numeric(str_extract(Westham_corpus_summary$Text, \"[0-9]+\"))\nWestham_corpus_summary\n\n\nCorpus consisting of 7 documents, showing 7 documents:\n\n  Text Types Tokens Sentences    Team Match\n text1   360    799        16 WestHam     1\n text2   339    759        18 WestHam     2\n text3   283    599        18 WestHam     3\n text4   325    730         7 WestHam     4\n text5   311    694        10 WestHam     5\n text6   338    696        10 WestHam     6\n text7   323    685         8 WestHam     7"
  },
  {
    "objectID": "posts/TextualAnalysis.html#exploratory-analysis",
    "href": "posts/TextualAnalysis.html#exploratory-analysis",
    "title": "Textual Analysis",
    "section": "Exploratory Analysis",
    "text": "Exploratory Analysis"
  },
  {
    "objectID": "posts/TextualAnalysis.html#bibliography",
    "href": "posts/TextualAnalysis.html#bibliography",
    "title": "Textual Analysis",
    "section": "Bibliography",
    "text": "Bibliography\n\nCity, M. (2022). NEWS. Retrieved from Mancity: https://www.mancity.com/news/mens\nClub, L. F. (2022). First Team. Retrieved from Leicester Football Club: https://www.lcfc.com/matches/reports\nClub, T. A. (2022). NEWS. Retrieved from Arsenal: https://www.arsenal.com/news?field_article_arsenal_team_value=men&revision_information=&page=1\nEverton. (2022). Results. Retrieved from Everton: https://www.evertonfc.com/results\nUnited, N. (2022). Our Results. Retrieved from Newcastle United: https://www.nufc.co.uk/matches/first-team/#results\nUnited, W. H. (2022). Fixtures. Retrieved from West Ham United: https://www.whufc.com/fixture/list/713"
  },
  {
    "objectID": "templates/AboutTemplate.html",
    "href": "templates/AboutTemplate.html",
    "title": "Your Name",
    "section": "",
    "text": "##Instructions"
  },
  {
    "objectID": "templates/AboutTemplate.html#educationwork-background",
    "href": "templates/AboutTemplate.html#educationwork-background",
    "title": "Your Name",
    "section": "Education/Work Background",
    "text": "Education/Work Background"
  },
  {
    "objectID": "templates/AboutTemplate.html#r-experience",
    "href": "templates/AboutTemplate.html#r-experience",
    "title": "Your Name",
    "section": "R experience",
    "text": "R experience"
  },
  {
    "objectID": "templates/AboutTemplate.html#research-interests",
    "href": "templates/AboutTemplate.html#research-interests",
    "title": "Your Name",
    "section": "Research interests",
    "text": "Research interests"
  },
  {
    "objectID": "templates/AboutTemplate.html#hometown",
    "href": "templates/AboutTemplate.html#hometown",
    "title": "Your Name",
    "section": "Hometown",
    "text": "Hometown"
  },
  {
    "objectID": "templates/AboutTemplate.html#hobbies",
    "href": "templates/AboutTemplate.html#hobbies",
    "title": "Your Name",
    "section": "Hobbies",
    "text": "Hobbies"
  },
  {
    "objectID": "templates/AboutTemplate.html#fun-fact",
    "href": "templates/AboutTemplate.html#fun-fact",
    "title": "Your Name",
    "section": "Fun fact",
    "text": "Fun fact"
  },
  {
    "objectID": "templates/PostTemplate.html",
    "href": "templates/PostTemplate.html",
    "title": "Blog Post Template",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "templates/PostTemplate.html#instructions",
    "href": "templates/PostTemplate.html#instructions",
    "title": "Blog Post Template",
    "section": "Instructions",
    "text": "Instructions\nThis document provides yaml header inforamtion you will need to replicate each week to submit your homework or other blog posts. Please observe the following conventions:\n\nSave your own copy of this template as a blog post in the posts folder.\nEdit the yaml header to change your author name\ninclude a description that is reader friendly\nupdate the category list to indicate what category is the blog post, the data used, the main packages or techniques, your name, or any thing else to make your document easy to find\nedit as a normal qmd/rmd file\n\n\n\nCode\nx <- c(2,3,4,5)\nmean(x)\n\n\n[1] 3.5"
  },
  {
    "objectID": "templates/PostTemplate.html#rendering-your-post",
    "href": "templates/PostTemplate.html#rendering-your-post",
    "title": "Blog Post Template",
    "section": "Rendering your post",
    "text": "Rendering your post\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code.\n\n\n\n\n\n\nWarning\n\n\n\nBe sure that you have moved your *.qmd file into the posts folder BEFORE you render it, so that all files are stored in the correct location.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nOnly render a single file - don’t try to render the whole website!\n\n\n\n\n\n\n\n\nPilot Student Blogs\n\n\n\nWe are piloting a workflow including individual student websites with direted and limited pull requests back to course blogs. Please let us know if you would like to participate."
  },
  {
    "objectID": "templates/PostTemplate.html#reading-in-data-files",
    "href": "templates/PostTemplate.html#reading-in-data-files",
    "title": "Blog Post Template",
    "section": "Reading in data files",
    "text": "Reading in data files\nThe easiest data source to use - at least initially - is to choose something easily accessible, either from our _data folder provided, or from an online source that is publicly available.\n\n\n\n\n\n\nUsing Other Data\n\n\n\nIf you would like to use a source that you have access to and it is small enough and you don’t mind making it public, you can copy it into the _data file and include in your commit and pull request.\n\n\n\n\n\n\n\n\nUsing Private Data\n\n\n\nIf you would like to use a proprietary source of data, that should be possible using the same process outlined above. There may initially be a few issues. We hope to have this feature working smoothly soon!"
  }
]