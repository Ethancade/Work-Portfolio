{
  "hash": "802e02de5baa790857a98ac65a44233a",
  "result": {
    "markdown": "---\ntitle: \"Textual Analysis\"\nauthor: \"Ethan Campbell\"\ndesription: \"Analyzing English premier league team's and how their langauge chagnes during the course of the season\"\ndate: \"10/30/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(echo = TRUE)\n```\n:::\n\n\n# Loading Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'rvest' was built under R version 4.1.3\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidyverse' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n-- Attaching packages --------------------------------------- tidyverse 1.3.2 --\nv ggplot2 3.3.6     v purrr   0.3.4\nv tibble  3.1.8     v dplyr   1.0.9\nv tidyr   1.2.0     v stringr 1.4.1\nv readr   2.1.2     v forcats 0.5.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ggplot2' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tibble' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidyr' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'readr' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'dplyr' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'stringr' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'forcats' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter()         masks stats::filter()\nx readr::guess_encoding() masks rvest::guess_encoding()\nx dplyr::lag()            masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(polite)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'polite' was built under R version 4.1.3\n```\n:::\n\n```{.r .cell-code}\nlibrary(stringr)\nlibrary(quanteda)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'quanteda' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in .recacheSubclasses(def@className, def, env): undefined subclass\n\"packedMatrix\" of class \"mMatrix\"; definition not updated\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in .recacheSubclasses(def@className, def, env): undefined subclass\n\"packedMatrix\" of class \"replValueSp\"; definition not updated\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nPackage version: 3.2.3\nUnicode version: 13.0\nICU version: 69.1\nParallel computing: 12 of 12 threads used.\nSee https://quanteda.io for tutorials and examples.\n```\n:::\n\n```{.r .cell-code}\nlibrary(quanteda.textplots)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'quanteda.textplots' was built under R version 4.1.3\n```\n:::\n:::\n\n\n# Data Sources\n\nThere are 6 teams included in this study 2 from the top of the table 2 from the middle and 2 from the bottom. They are already in that order from top to bottom. Data needed to be web scraped from a page called match report. This page was located on each teams official website and this page included information about the match, statistics, and quotes from both the players and the managers.\n\n[Arsenal Data](https://www.arsenal.com/news?field_article_arsenal_team_value=men&revision_information=&page=1)\n\n[Manchester City Data](https://www.mancity.com/news/mens)\n\n[Newcastle United Data](https://www.nufc.co.uk/matches/first-team/#results)\n\n[Everton Data](https://www.evertonfc.com/results)\n\n[Leicester Data](https://www.lcfc.com/matches/reports)\n\n[West Ham United Data](https://www.whufc.com/fixture/list/713)\n\n\n# Analytical planning\n\n\n```{mermaid}\nflowchart LR\n  A[Web Scrape] --> B(Preprocess)\n  B --> C[Organize]\n  C --> D(TDM)\n  D --> E[Sentiment Analysis]\n  E --> F[Research Question 1]\n  F --> G{Conclusion}\n  D --> H[DTM]\n  H --> I[Document Similarity]\n  I --> J[Research Question 2]\n  J --> G{Conclusion}\n```\n\n\n# Web Scraping/Tidying data\n\nHere is the beginning of the web scraping process. I was unable to find a way to make the web scraper search for one object then proceed to the next page where you could then scrape whats inside. For the time being I decided to manually web scrape the information. The tidying process is the real issue as there are many unwanted variables inside. For example there are a lot of /n's.\n\n## Arsenal\n\nThis data was scraped from the official Arsenal page. This scraping pulled in all the matches that have been played this season thus far and will continue to grow as the season progresses. Within this scraped data there was a lot that needed to get removed which included things like /n, \\n, random number strings, and long sentences talking about buying Arsenal pictures. After using stringr to clean up the data we unlisted it and started moving towards a corpus. There is still some tidying that needs to be done to remove some -'s and to make some spaces at certain portion of the document. After cleaning this data was put into a character vector and then put into a corpus which can be found at the bottom of this code. I added in the name of the team and the match number to the table and after that we can start looking at what the data means. So far 7 matches have been played and the word count was kept fairly consistent until match 5\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## The function is working at reading in the data however. parts of the cleaning process are failing and I am thinking this is because I am not specifying the create values\n\n# I need to remove punct, capitalization, stopwords like (the, a ',') finish repeating the process to all teams and adjusting the function until it grabs every single problem once this is complete we should be able to tokenize then corpus and work with the data\n\nWeb_scrape_function_Arsenal <- function(url,css,data) { # creating function to repeat web scrape \n  url <- read_html(url) \ncss <- (\".article-body\")\ndata <- url %>% \n  html_node(css = css) %>%\n  html_text2()\ndata <- str_replace_all(data, \"\\n\", \"####\") %>%\n  str_replace_all(\"/n\", \"####\") %>%\n  str_remove_all(\"/n\") %>%\n  str_remove_all(\"\\n\") %>%\n  str_remove_all(\" - \") %>%\n  str_replace_all(\"[0-9] of [1234567890]To buy official Arsenal pictures visit Arsenal Pics\", \"#\") %>%\n  str_replace_all(\"[1234567890] of 42To buy official Arsenal pictures visit Arsenal Pics\", \"#\") %>%\n  str_replace_all(\"[1234567890] of 29To buy official Arsenal pictures visit Arsenal Pics\", \"#\") %>%\n  str_replace_all(\"[1234567890] of 45To buy official Arsenal pictures visit Arsenal Pics\", \"#\") %>%\n  str_replace_all(\"[1234567890] of 38To buy official Arsenal pictures visit Arsenal Pics\", \"#\") %>%\n  str_replace_all(\"[1234567890] of 32To buy official Arsenal pictures visit Arsenal Pics\", \"#\") %>%\n  str_remove(\"Play videoWatch Arsenal video online05:24Highlights | Crystal Palace 0-2 Arsenal - bitesize\") %>%\n  str_remove(\"111111111122222222223333333333444\") %>%\n  str_remove_all(\"\\\\(\") %>%\n  str_remove_all(\"\\\\)\") %>%\n  str_remove_all(\"#\") %>%\n  unlist()\n}\n\n\nArsenal_url <- \"https://www.arsenal.com/fixture/arsenal/2022-Aug-05/crystal-palace-0-2-arsenal-match-report\"\nMatch_1 <- Web_scrape_function_Arsenal(Arsenal_url)\n\nArsenal_url <- \"https://www.arsenal.com/fixture/arsenal/2022-Aug-13/arsenal-4-2-leicester-city-match-report\"\nMatch_2 <- Web_scrape_function_Arsenal(Arsenal_url)\n\n\nArsenal_url <- \"https://www.arsenal.com/premier-league-match-report-bournemouth-odegaard-saliba-jesus\"\nMatch_3 <- Web_scrape_function_Arsenal(Arsenal_url)\n\nArsenal_url <- \"https://www.arsenal.com/premier-league-match-report-fulham-odegaard-gabriel\"\nMatch_4 <- Web_scrape_function_Arsenal(Arsenal_url)\n\nArsenal_url <- \"https://www.arsenal.com/match-report-aston-villa-premier-league-martinelli-jesus\"\nMatch_5 <- Web_scrape_function_Arsenal(Arsenal_url)\n\nArsenal_url <- \"https://www.arsenal.com/fixture/arsenal/2022-Sep-04/manchester-united-3-1-arsenal-match-report\"\nMatch_6 <- Web_scrape_function_Arsenal(Arsenal_url)\n\nArsenal_url <- \"https://www.arsenal.com/premier-league-match-report-brentford-saliba-jesus-vieira\"\nMatch_7 <- Web_scrape_function_Arsenal(Arsenal_url)\n\nArsenal <- c(Match_1, Match_2, Match_3, Match_4, Match_5, Match_6, Match_7)\n\nnchar(Arsenal)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 8163 9066 7726 7601 4433 7322 7818\n```\n:::\n\n```{.r .cell-code}\nArsenal_corpus <- corpus(Arsenal)\n\n\n\nArsenal_corpus_summary <- summary(Arsenal_corpus)\ndocvars(Arsenal_corpus) <- Arsenal_corpus_summary\n# Adding team name\nArsenal_corpus_summary$Team <- \"Arsenal\"\n\n\n# create a Match number\nArsenal_corpus_summary$Match <- as.numeric(str_extract(Arsenal_corpus_summary$Text, \"[0-9]+\"))\nArsenal_corpus_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCorpus consisting of 7 documents, showing 7 documents:\n\n  Text Types Tokens Sentences    Team Match\n text1   523   1412        11 Arsenal     1\n text2   602   1623        22 Arsenal     2\n text3   551   1387        15 Arsenal     3\n text4   479   1299         9 Arsenal     4\n text5   408    790        12 Arsenal     5\n text6   481   1258         6 Arsenal     6\n text7   526   1395        21 Arsenal     7\n```\n:::\n\n```{.r .cell-code}\n# Document feature matrix\nArsenal_dfm <- dfm(tokens(Arsenal_corpus,\n                          remove_punct = TRUE,\n                          remove_symbols = TRUE) %>%\n                     dfm(tolower = TRUE) %>%\n                     dfm_remove(stopwords('english')))\n\nview(Arsenal_dfm)\n\ntopfeatures(Arsenal_dfm, 20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n arsenal official      buy pictures    visit   league    first  premier \n     475      223      222      222      222       63       60       57 \n minutes     45to     42to     38to     36to     goal    jesus     32to \n      49       45       42       38       36       33       33       32 \n      us     ball     back     29to \n      31       31       29       29 \n```\n:::\n\n```{.r .cell-code}\nset.seed(1)\n\n# draw the wordcloud\ntextplot_wordcloud(Arsenal_dfm, min_count = 20, random_order = FALSE)\n```\n\n::: {.cell-output-display}\n![](TextualAnalysis_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# comparing the first and last game\n\nArsenal_small_dfm <- Arsenal_dfm[c(1,7),]\n\n# draw the wordcloud\ntextplot_wordcloud(Arsenal_small_dfm, comparison = TRUE, min_count = 5, random_order = FALSE)\n```\n\n::: {.cell-output-display}\n![](TextualAnalysis_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Creating a table to show the highest frequncy items and then ranking them\nword_counts <- as.data.frame(sort(colSums(Arsenal_dfm),dec=T))\ncolnames(word_counts) <- c(\"Frequency\")\nword_counts$Rank <- c(1:ncol(Arsenal_dfm))\nhead(word_counts)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Frequency Rank\narsenal        475    1\nofficial       223    2\nbuy            222    3\npictures       222    4\nvisit          222    5\nleague          63    6\n```\n:::\n\n```{.r .cell-code}\n# zipf's law is really quite accurate as the data does fall off really quickly\nggplot(word_counts, mapping = aes(x = Rank, y = Frequency)) + \n  geom_point() +\n  labs(title = \"Zipf's Law\", x = \"Rank\", y = \"Frequency\") + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](TextualAnalysis_files/figure-html/unnamed-chunk-4-3.png){width=672}\n:::\n\n```{.r .cell-code}\nArsenal_smaller_dfm <- dfm_trim(Arsenal_dfm, min_termfreq = 10)\n\n# trim based on the proportion of documents that the feature appears in; here, \n# the feature needs to appear in more than 10% of documents (chapters)\nArsenal_smaller_dfm <- dfm_trim(Arsenal_smaller_dfm, min_docfreq = 0.1, docfreq_type = \"prop\")\n\nArsenal_smaller_dfm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDocument-feature matrix of: 7 documents, 67 features (18.12% sparse) and 4 docvars.\n       features\ndocs    gabriel martinelli header goal premier league start win home minutes\n  text1       2          3      2    6       9      8     4   3    3      10\n  text2       3          6      3    4       5      5     2   1    3       9\n  text3       3          3      1    8      10     11     5   2    1       7\n  text4       7          4      2    4       8      8     3   3    3       9\n  text5       4          5      0    5       7      9     1   0    0       5\n  text6       2          5      1    5       5      7     2   1    0       6\n[ reached max_ndoc ... 1 more document, reached max_nfeat ... 57 more features ]\n```\n:::\n\n```{.r .cell-code}\ntextplot_wordcloud(Arsenal_smaller_dfm, min_count = 50,\n                   random_order = FALSE)\n```\n\n::: {.cell-output-display}\n![](TextualAnalysis_files/figure-html/unnamed-chunk-4-4.png){width=672}\n:::\n\n```{.r .cell-code}\n# Creating the FCM\n\nArsenal_smaller_dfm <- dfm_trim(Arsenal_dfm, min_termfreq = 20)\nArsenal_smaller_dfm <- dfm_trim(Arsenal_smaller_dfm, min_docfreq = .3, docfreq_type = \"prop\")\n\n# create fcm from dfm\nArsenal_smaller_dfm <- fcm(Arsenal_smaller_dfm)\n\n# check the dimensions (i.e., the number of rows and the number of columnns)\n# of the matrix we created\ndim(Arsenal_smaller_dfm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 22 22\n```\n:::\n\n```{.r .cell-code}\n# pull the top features\nmyFeatures <- names(topfeatures(Arsenal_smaller_dfm, 30))\n\n# retain only those top features as part of our matrix\nArsenal_smaller_dfm <- fcm_select(Arsenal_smaller_dfm, pattern = myFeatures, selection = \"keep\")\n\n# check dimensions\ndim(Arsenal_smaller_dfm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 22 22\n```\n:::\n\n```{.r .cell-code}\n# compute size weight for vertices in network\nsize <- log(colSums(Arsenal_smaller_dfm))\n\n# create plot\ntextplot_network(Arsenal_smaller_dfm, vertex_size = size / max(size) * 3)\n```\n\n::: {.cell-output-display}\n![](TextualAnalysis_files/figure-html/unnamed-chunk-4-5.png){width=672}\n:::\n:::\n\n\n## Manchester City\n\nManchester Cty followed a very similar path as Arsenal as this one also required a lot cleaning with stringr however, it had a few unique moments. For example, I had to clean () which were all over the place in the original data. Other than this portion the cleaning process was the same and this will also needs some additional cleaning. I was able to move this into the corpus as well and we noticed that it had more sentences than Arsenal. However, this could be do to the spacing problem that I mentioned above more studying will need to be done after that change has been made. This team also had a more consistent amount of words and unique words.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nWeb_scrape_function_mancity <- function(url,css,data) { # creating function to repeat web scrape \n  url <- read_html(url) \ncss <- (\".article-body__article-text\")\ndata <- url %>% \n  html_node(css = css) %>%\n  html_text2()\ndata <- str_replace_all(data, \"\\n\", \"####\") %>%\n  str_replace_all(\"/n\", \"####\") %>%\n  str_remove_all(\"/n\") %>%\n  str_remove_all(\"\\n\") %>%\n  str_remove_all(\" - \") %>%\n  str_remove_all(\"\\\\(\") %>%\n  str_remove_all(\"\\\\)\") %>%\n  str_remove_all(\"#\") %>%\n  unlist()\n}\n\nmancity_url <- \"https://www.mancity.com/news/mens/west-ham-v-manchester-city-premier-league-match-report-63795480\"\nMatch_1 <- Web_scrape_function_mancity(mancity_url)\n\nmancity_url <- \"https://www.mancity.com/news/mens/man-city-bournemouth-premier-league-match-report-63795987\"\nMatch_2 <- Web_scrape_function_mancity(mancity_url)\n\nmancity_url <- \"https://www.mancity.com/news/mens/newcastle-v-manchester-city-match-report-63796690\"\nMatch_3 <- Web_scrape_function_mancity(mancity_url)\n\nmancity_url <- \"https://www.mancity.com/news/mens/man-city-crystal-palace-match-report-63797204\"\nMatch_4 <- Web_scrape_function_mancity(mancity_url)\n\nmancity_url <- \"https://www.mancity.com/news/mens/manchester-city-v-nottingham-forest-match-report-31-august-63797573\"\nMatch_5 <- Web_scrape_function_mancity(mancity_url)\n\nmancity_url <- \"https://www.mancity.com/news/mens/aston-villa-manchester-city-premier-league-match-report-63797816\"\nMatch_6 <- Web_scrape_function_mancity(mancity_url)\n\nmancity_url <- \"https://www.mancity.com/news/mens/wolves-manchester-city-away-premier-league-2022-match-report-63799002\"\nMatch_7 <- Web_scrape_function_mancity(mancity_url)\n\n\nManCity <- c(Match_1, Match_2, Match_3, Match_4, Match_5, Match_6, Match_7)\n\nMancity_corpus <- corpus(ManCity)\n\nMancity_corpus_summary <- summary(Mancity_corpus)\n\n# Creating a Team Name \nMancity_corpus_summary$Team <- \"Manchester City\"\n\n# create a Match number\nMancity_corpus_summary$Match <- as.numeric(str_extract(Mancity_corpus_summary$Text, \"[0-9]+\"))\nMancity_corpus_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCorpus consisting of 7 documents, showing 7 documents:\n\n  Text Types Tokens Sentences            Team Match\n text1   564   1270        21 Manchester City     1\n text2   615   1482        28 Manchester City     2\n text3   660   1462        20 Manchester City     3\n text4   550   1218        23 Manchester City     4\n text5   489   1126        34 Manchester City     5\n text6   662   1744        60 Manchester City     6\n text7   703   1724        34 Manchester City     7\n```\n:::\n:::\n\n\n## Newcastle united\n\nThis is the start of the middle table teams which I am exciting to see how they differ the two top tier teams. This data was scraped from the Newcastle official website and the cleaning process was pretty straight forward on this one as there was nothing unique that needed to be changed. One noticeable difference between this team and the top teams is the amount of words used in match reports as this one is about half of the first two teams. This might be unique to just this team or maybe the lower in the league the team is the less they will write about their performance?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# New Castle United first match against nottingham forest\n# 1 rule for 1 bots crawl delay 5 seconds, scrapable\n\nbow(\"https://www.nufc.co.uk/matches/first-team/2022-23/newcastle-united-v-nottingham-forest/\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<polite session> https://www.nufc.co.uk/matches/first-team/2022-23/newcastle-united-v-nottingham-forest/\n    User-agent: polite R package\n    robots.txt: 1 rules are defined for 1 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n```\n:::\n\n```{.r .cell-code}\nWeb_scrape_function_Newcastle <- function(url,css,data) { # creating function to repeat web scrape \n  url <- read_html(url) \ncss <- (\".article__body\")\ndata <- url %>% \n  html_node(css = css) %>%\n  html_text2()\ndata <- str_replace_all(data, \"\\n\", \"####\") %>%\n  str_replace_all(\"/n\", \"####\") %>%\n  str_remove_all(\"/n\") %>%\n  str_remove_all(\"\\n\") %>%\n  str_remove_all(\" - \") %>%\n  str_remove_all(\"\\\\(\") %>%\n  str_remove_all(\"\\\\)\") %>%\n  str_remove_all(\"\\\"\") %>%\n  str_remove_all(\"#\") %>%\n  unlist()\n}\n\nNewcastle_url <- \"https://www.nufc.co.uk/matches/first-team/2022-23/newcastle-united-v-nottingham-forest/\"\nMatch_1 <- Web_scrape_function_Newcastle(Newcastle_url)\n\nNewcastle_url <- \"https://www.nufc.co.uk/matches/first-team/2022-23/brighton-and-hove-albion-v-newcastle-united/\"\nMatch_2 <- Web_scrape_function_Newcastle(Newcastle_url)\n\nNewcastle_url <- \"https://www.nufc.co.uk/matches/first-team/2022-23/newcastle-united-v-manchester-city/\"\nMatch_3 <- Web_scrape_function_Newcastle(Newcastle_url)\n\nNewcastle_url <- \"https://www.nufc.co.uk/matches/first-team/2022-23/wolverhampton-wanderers-v-newcastle-united/\"\nMatch_4 <- Web_scrape_function_Newcastle(Newcastle_url)\n\nNewcastle_url <- \"https://www.nufc.co.uk/matches/first-team/2022-23/liverpool-v-newcastle-united/\"\nMatch_5 <- Web_scrape_function_Newcastle(Newcastle_url)\n\nNewcastle_url <- \"https://www.nufc.co.uk/matches/first-team/2022-23/newcastle-united-v-crystal-palace/\"\nMatch_6 <- Web_scrape_function_Newcastle(Newcastle_url)\n\nNewcastle_url <- \"https://www.nufc.co.uk/matches/first-team/2022-23/newcastle-united-v-bournemouth/\"\nMatch_7 <- Web_scrape_function_Newcastle(Newcastle_url)\n\nNewCastle <- c(Match_1, Match_2, Match_3, Match_4, Match_5, Match_6, Match_7)\n\nNewcastle_corpus <- corpus(NewCastle)\n\nNewcastle_corpus_summary <- summary(Newcastle_corpus)\n\n# Creating a team name\nNewcastle_corpus_summary$Team <- \"New Castle\"\n\n# create a Match number\nNewcastle_corpus_summary$Match <- as.numeric(str_extract(Newcastle_corpus_summary$Text, \"[0-9]+\"))\nNewcastle_corpus_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCorpus consisting of 7 documents, showing 7 documents:\n\n  Text Types Tokens Sentences       Team Match\n text1   336    665        11 New Castle     1\n text2   339    625        18 New Castle     2\n text3   340    677        12 New Castle     3\n text4   294    539         8 New Castle     4\n text5   324    615         8 New Castle     5\n text6   360    729         4 New Castle     6\n text7   377    741        19 New Castle     7\n```\n:::\n:::\n\n\n## Everton\n\nWas going to use Aston Villa originally however, the web scrapping was not returning the correct information so we switched to Everton which is running much more smoothly. This is the second team on the list of middle-tier teams and their cleaning process was about the same as the last team however, Aston Villa's website was really hard to scrape from. Looking at the corpus information for Everton we notice an increase in words compared to the last team however, there is one match that is significantly higher than the rest. This is match 2 which was against Aston Villa and I am currently unsure why there is such a difference between these amounts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Everton vs Chelsea\n# 1 rule for 1 bots crawl delay 5 seconds, scrapable\n\nbow(\"https://www.evertonfc.com/match/74913/everton-chelsea#report\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<polite session> https://www.evertonfc.com/match/74913/everton-chelsea#report\n    User-agent: polite R package\n    robots.txt: 1 rules are defined for 1 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n```\n:::\n\n```{.r .cell-code}\nWeb_scrape_function_Everton <- function(url,css,data) { # creating function to repeat web scrape \n  url <- read_html(url) \ncss <- (\".article__body.mc-report__body.js-article-body\")\ndata <- url %>% \n  html_node(css = css) %>%\n  html_text2()\ndata <- str_replace_all(data, \"\\n\", \"####\") %>%\n  str_replace_all(\"/n\", \"####\") %>%\n  str_remove_all(\"/n\") %>%\n  str_remove_all(\"\\n\") %>%\n  str_remove_all(\" - \") %>%\n  str_remove_all(\"\\\\(\") %>%\n  str_remove_all(\"\\\\)\") %>%\n  str_remove_all(\"\\\"\") %>%\n  str_remove_all(\"#\") %>%\n  unlist()\n}\n\nEverton_url <- \"https://www.evertonfc.com/match/74913/everton-chelsea#report\"\nMatch_1 <- Web_scrape_function_Everton(Everton_url)\n\nEverton_url <- \"https://www.evertonfc.com/match/74922/aston-villa-everton#report\"\nMatch_2 <- Web_scrape_function_Everton(Everton_url)\n\nEverton_url <- \"https://www.evertonfc.com/match/74933/everton-nottm-forest#report\"\nMatch_3 <- Web_scrape_function_Everton(Everton_url)\n\nEverton_url <-\"https://www.evertonfc.com/match/74943/brentford-everton#report\"\nMatch_4 <- Web_scrape_function_Everton(Everton_url)\n\nEverton_url <- \"https://www.evertonfc.com/match/74955/leeds-everton#report\"\nMatch_5 <- Web_scrape_function_Everton(Everton_url)\n\nEverton_url <- \"https://www.evertonfc.com/match/74965/everton-liverpool#report\"\nMatch_6 <- Web_scrape_function_Everton(Everton_url)\n\nEverton_url <- \"https://www.evertonfc.com/match/74985/everton-west-ham#report\"\nMatch_7 <- Web_scrape_function_Everton(Everton_url)\n\n\nEverton <- c(Match_1, Match_2, Match_3, Match_4, Match_5, Match_6, Match_7)\n\nEverton_corpus <- corpus(Everton)\n\nEverton_corpus_summary <- summary(Everton_corpus)\n\n# Creating a team name\nEverton_corpus_summary$Team <- \"Everton\"\n\n# create a match indicator\nEverton_corpus_summary$Match <- as.numeric(str_extract(Everton_corpus_summary$Text, \"[0-9]+\"))\nEverton_corpus_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCorpus consisting of 7 documents, showing 7 documents:\n\n  Text Types Tokens Sentences    Team Match\n text1   516    990         6 Everton     1\n text2   703   1577        13 Everton     2\n text3   330    624         1 Everton     3\n text4   340    614         3 Everton     4\n text5   374    709         4 Everton     5\n text6   418    872         4 Everton     6\n text7   438    874        10 Everton     7\n```\n:::\n:::\n\n\n## Leicester\n\nThis is the start of the bottom tier teams and we start to get a look into teams that are in the relegation zone which means that if they do not start improving their performance they will get moved down to the second league. I am expecting some urgency from this team and I am expecting that each match means a lot more to a team like this where one win can seperate you from staying or getting kicked out of the league. The cleaning process went smoothly with this team but there is deffiently still some work that needs to be done before the real analysis. We noticed that there words used was higher than the two middle teams on average and they had a pretty consistent range.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Leicester against Brentford\n# 1 bot 1 rule scrapable 5 second crawl\nbow(\"https://www.lcfc.com/news/2729025/city-held-by-bees-in-premier-league-opener/featured\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<polite session> https://www.lcfc.com/news/2729025/city-held-by-bees-in-premier-league-opener/featured\n    User-agent: polite R package\n    robots.txt: 1 rules are defined for 1 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n```\n:::\n\n```{.r .cell-code}\nWeb_scrape_function_Leicester <- function(url,css,data) { # creating function to repeat web scrape \n  url <- read_html(url) \ncss <- (\".col-12\")\ndata <- url %>% \n  html_node(css = css) %>%\n  html_text2()\ndata <- str_replace_all(data, \"\\n\", \"####\") %>%\n  str_replace_all(\"/n\", \"####\") %>%\n  str_remove_all(\"/n\") %>%\n  str_remove_all(\"\\n\") %>%\n  str_remove_all(\" - \") %>%\n  str_remove_all(\"\\\\(\") %>%\n  str_remove_all(\"\\\\)\") %>%\n  str_remove_all(\"\\\"\") %>%\n  str_remove_all(\"#\") %>%\n  str_remove_all(\"More on this story. . . In Photos -\") %>%\n  unlist()\n}\n\nLeicester_url <- \"https://www.lcfc.com/news/2729025/city-held-by-bees-in-premier-league-opener/featured\"\nMatch_1 <- Web_scrape_function_Leicester(Leicester_url)\n\nLeicester_url <- \"https://www.lcfc.com/news/2739798/foxes-fall-to-defeat-at-arsenal/featured\"\nMatch_2 <- Web_scrape_function_Leicester(Leicester_url)\n\nLeicester_url <- \"https://www.lcfc.com/news/2751347/saints-take-the-points-on-filbert-way/featured\"\nMatch_3 <- Web_scrape_function_Leicester(Leicester_url)\n\nLeicester_url <- \"https://www.lcfc.com/news/2762326/city-defeated-as-10man-chelsea-win-at-stamford-bridge/featured\"\nMatch_4 <- Web_scrape_function_Leicester(Leicester_url)\n\nLeicester_url <- \"https://www.lcfc.com/news/2774578/man-utd-defeat-for-leicester-on-matchday-five/featured\"\nMatch_5 <- Web_scrape_function_Leicester(Leicester_url)\n\nLeicester_url <- \"https://www.lcfc.com/news/2779658/city-beaten-away-to-brighton/featured\"\nMatch_6 <- Web_scrape_function_Leicester(Leicester_url)\n\nLeicester_url <- \"https://www.lcfc.com/news/2793845/leicester-lose-to-spurs-in-london/featured\"\nMatch_7 <- Web_scrape_function_Leicester(Leicester_url)\n\nLeicester <- c(Match_1, Match_2, Match_3, Match_4, Match_5, Match_6, Match_7)\n\nLeicester_corpus <- corpus(Leicester)\n\nLeicester_corpus_summary <- summary(Leicester_corpus)\n\n# Creating a team name\nLeicester_corpus_summary$Team <- \"Leicester\"\n\n# create a match indicator\nLeicester_corpus_summary$Match <- as.numeric(str_extract(Leicester_corpus_summary$Text, \"[0-9]+\"))\nLeicester_corpus_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCorpus consisting of 7 documents, showing 7 documents:\n\n  Text Types Tokens Sentences      Team Match\n text1   533   1143        26 Leicester     1\n text2   539   1183        18 Leicester     2\n text3   484   1043        39 Leicester     3\n text4   557   1263        27 Leicester     4\n text5   463    830        36 Leicester     5\n text6   498   1071        20 Leicester     6\n text7   481    999        26 Leicester     7\n```\n:::\n:::\n\n\n## West Ham United\n\nWest Ham was fairly straight forward and I was able to clean this one pretty well. There is still some spacing work that needs to be done but that will come at a later stage. When looking at their information we noticed that they use some of the least amount of words when talking about the matches. They also use some of the least unique words so I am interested to break this one down and see if they are mostly talking about certain players performances.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# West Ham vs Manchester City\n\nWeb_scrape_function_WestHam <- function(url,css,data) { # creating function to repeat web scrape \n  url <- read_html(url) \ncss <- (\".m-article__columns\")\ndata <- url %>% \n  html_node(css = css) %>%\n  html_text2()\ndata <- str_replace_all(data, \"\\n\", \"####\") %>%\n  str_replace_all(\"/n\", \"####\") %>%\n  str_remove_all(\"/n\") %>%\n  str_remove_all(\"\\n\") %>%\n  str_remove_all(\" - \") %>%\n  str_remove_all(\"\\\\(\") %>%\n  str_remove_all(\"\\\\)\") %>%\n  str_remove_all(\"\\\"\") %>%\n  str_remove_all(\"#\") %>%\n  str_remove_all(\"More on this story. . . In Photos -\") %>%\n  unlist()\n}\n\nWestHam_url <- \"https://www.whufc.com/fixture/view/6472\"\nMatch_1 <- Web_scrape_function_WestHam(WestHam_url)\n\nWestHam_url <- \"https://www.whufc.com/fixture/view/6464\"\nMatch_2 <- Web_scrape_function_WestHam(WestHam_url)\n\nWestHam_url <- \"https://www.whufc.com/fixture/view/6452\"\nMatch_3 <- Web_scrape_function_WestHam(WestHam_url)\n\nWestHam_url <- \"https://www.whufc.com/fixture/view/6450\"\nMatch_4 <- Web_scrape_function_WestHam(WestHam_url)\n\nWestHam_url <- \"https://www.whufc.com/fixture/view/6436\"\nMatch_5 <- Web_scrape_function_WestHam(WestHam_url)\n\nWestHam_url <- \"https://www.whufc.com/fixture/view/6428\"\nMatch_6 <- Web_scrape_function_WestHam(WestHam_url)\n\nWestHam_url <- \"https://www.whufc.com/fixture/view/6407\"\nMatch_7 <- Web_scrape_function_WestHam(WestHam_url)\n\n\nWestham <- c(Match_1, Match_2, Match_3, Match_4, Match_5, Match_6, Match_7)\n\nWestham_corpus <- corpus(Westham)\n\nWestham_corpus_summary <- summary(Westham_corpus)\n\n# Creating a team name\nWestham_corpus_summary$Team <- \"WestHam\"\n\n\n# create a match indicator\nWestham_corpus_summary$Match <- as.numeric(str_extract(Westham_corpus_summary$Text, \"[0-9]+\"))\nWestham_corpus_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCorpus consisting of 7 documents, showing 7 documents:\n\n  Text Types Tokens Sentences    Team Match\n text1   360    799        16 WestHam     1\n text2   339    759        18 WestHam     2\n text3   283    599        18 WestHam     3\n text4   325    730         7 WestHam     4\n text5   311    694        10 WestHam     5\n text6   338    696        10 WestHam     6\n text7   323    685         8 WestHam     7\n```\n:::\n:::\n\n\n## Exploratory Analysis\n\n## Bibliography\n\n-   City, M. (2022). NEWS. Retrieved from Mancity: https://www.mancity.com/news/mens\n\n-   Club, L. F. (2022). First Team. Retrieved from Leicester Football Club: https://www.lcfc.com/matches/reports\n\n-   Club, T. A. (2022). NEWS. Retrieved from Arsenal: https://www.arsenal.com/news?field_article_arsenal_team_value=men&revision_information=&page=1\n\n-   Everton. (2022). Results. Retrieved from Everton: https://www.evertonfc.com/results\n\n-   United, N. (2022). Our Results. Retrieved from Newcastle United: https://www.nufc.co.uk/matches/first-team/#results\n\n-   United, W. H. (2022). Fixtures. Retrieved from West Ham United: https://www.whufc.com/fixture/list/713\n",
    "supporting": [
      "TextualAnalysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}